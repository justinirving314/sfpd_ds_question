{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a281c8fe",
   "metadata": {},
   "source": [
    "# Description of Notebook\n",
    "- This notebook extracts data from SF Gov, does spatial joins as needed, makes a few data type adjustment, and loads the data into a local Postgres database for further transformations and hosting for the final analysis. \n",
    "- The data pulled includes active parcels, fire incidents, fire inspections, fire inspection violations, DBI inspection complaints, DBI violations, and Tax Assessor Information (2014) to provide additional metadata.\n",
    "- Our main goal for this project is to help the SFFD and DBI prioritize their R-2 property inspections which are required annually and at least every five years respectively. \n",
    "- The goal of prioriziation is to identify the highest risk buildings and prioritize those first.\n",
    "- Functions are included in the module/pipeline_module.py file\n",
    "\n",
    "## Next Steps For Notebook\n",
    "- Clean up code and functionalize more in this notebook to improve readability and repeatability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b632cf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "# Navigate up one level in the directory hierarchy\n",
    "parent_dir = os.path.abspath(os.path.join(cwd, '..'))\n",
    "relative_path = os.path.join(parent_dir+'/modules/')\n",
    "sys.path.append(relative_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d2add2",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82c94dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pipeline_module import pull_opensf_data\n",
    "from pipeline_module import extract_coordinates\n",
    "from pipeline_module import shape_extract\n",
    "from pipeline_module import spatial_join\n",
    "from pipeline_module import upload_to_postgres\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import ast\n",
    "import json\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import shape\n",
    "from shapely.geometry import Point\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d48c679",
   "metadata": {},
   "source": [
    "# Import Data from API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e87c97",
   "metadata": {},
   "source": [
    "## Define common variables for all API pulls\n",
    "- This includes the site and required keys.\n",
    "- Additional users would need to create a .env file in their cloned repo and add their unique keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13ec6161",
   "metadata": {},
   "outputs": [],
   "source": [
    "#website for Socrata API \n",
    "site = 'data.sfgov.org'\n",
    "\n",
    "#Credentials loaded from .env file, new users of this notebook must create their own credentials and .env file\n",
    "#after cloning the gitrepo\n",
    "load_dotenv()\n",
    "app_token = os.getenv('SFDATA_APP_TOKEN')\n",
    "api_key_id = os.getenv('SFDATA_KEY_ID')\n",
    "api_secret_key = os.getenv('SFDATA_SECRET_KEY')\n",
    "postgres_connstr = os.getenv('POST_CONN_STR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12aae6d1",
   "metadata": {},
   "source": [
    "## Import Parcel Data\n",
    "- Some of the data sets we're working with do not have parcel number included (e.g. fire incident/inspection reports). We will need to spatially join those points with the parcel polygons so we have parcel number included with the records for subsequent joins to assessor data for additional metadata.\n",
    "- We will also join to DBI/HIS inspection data to confirm our spatial join method against block/lot in those datasets.\n",
    "- We have started with just active parcels. However, we could go back in the future and incorporate a time element to our joins for improved accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e810708d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull parcel data from the API \n",
    "parcel_endpoint = 'acdm-wktn'\n",
    "pulltype = 'all' #pull all parcels available in dataset\n",
    "filters = 'active=True' #filter so that we're only pulling active parcels. \n",
    "                        #It could be more accurate to pull historical parcels and match on year but this is for first pass analysis.\n",
    "\n",
    "parcels_df = pull_opensf_data(site, \n",
    "                              parcel_endpoint, \n",
    "                              app_token, \n",
    "                              api_key_id, \n",
    "                              api_secret_key,\n",
    "                              pulltype,\n",
    "                              filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b204f087",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform initial transformations on parcels dataframe and get it ready for spatial joins\n",
    "final_parcels_df = parcels_df.rename(columns={'mapblklot':'parcel_number'}) #rename for clarity and later joins\n",
    "final_parcels_df = final_parcels_df[['parcel_number','shape']] #Drop other columns as we're just using this to match parcel_number with points\n",
    "final_parcels_df['geometry'] = final_parcels_df['shape'].apply(shape_extract) #convert to shape using shapely for spatial joins "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac9ce5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_parcels_df = final_parcels_df.drop(['shape'],axis=1).drop_duplicates() #drop duplicates from other columns that aren't parcel and polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cfec32",
   "metadata": {},
   "source": [
    "## Import Fire Incidents Data\n",
    "- Import fire incidents from API and join with final_parcels_df as no parcel number was found in data\n",
    "- Perform data preprocessing to ensure database contains proper datatypes and no formats that cannot be stored. \n",
    "- Export results to Postgres database for further processing (transformations) in SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8700024",
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_incidents_endpoint = 'wr8u-xric' #Fire incidents endpoint\n",
    "pulltype = 'all' #pull all parcels available in dataset\n",
    "filters = 'area_of_fire_origin IS NOT NULL' #This filter removes incidents that are not related to fire (e.g. EMS, etc.)\n",
    "fire_incidents_df = pull_opensf_data(site, \n",
    "                                     fire_incidents_endpoint, \n",
    "                                     app_token, \n",
    "                                     api_key_id, \n",
    "                                     api_secret_key,\n",
    "                                     pulltype,\n",
    "                                     filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09a0b83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing to make sure our date types transfer correctly\n",
    "fire_incidents_df['incident_number'] = fire_incidents_df['incident_number'].astype(int)\n",
    "fire_incidents_df['exposure_number'] = fire_incidents_df['exposure_number'].astype(int)\n",
    "fire_incidents_df['exposure_number'] = fire_incidents_df['exposure_number'].astype(str)\n",
    "fire_incidents_df['address'] = fire_incidents_df['address'].astype(str)\n",
    "fire_incidents_df['incident_date'] = pd.to_datetime(fire_incidents_df['incident_date'])\n",
    "fire_incidents_df['alarm_dttm'] = pd.to_datetime(fire_incidents_df['alarm_dttm'])\n",
    "fire_incidents_df['arrival_dttm'] = pd.to_datetime(fire_incidents_df['arrival_dttm'])\n",
    "fire_incidents_df['close_dttm'] = pd.to_datetime(fire_incidents_df['close_dttm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e288fac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_txt = 'point'\n",
    "fire_incidents_df, fire_incidents_parcel_df = spatial_join(fire_incidents_df, \n",
    "                                                           spatial_txt, \n",
    "                                                           final_parcels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b39b527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36806\n",
      "36640\n",
      "36891\n",
      "36640\n"
     ]
    }
   ],
   "source": [
    "#Check if we're duplicating data. This is looking OK, a few duplicates but nothing to worry too much about at this point\n",
    "#There are a few points mapping to multiple parcels but we can take care of that later. If this was a longer project\n",
    "#Could do some additional spatial logic to make sure mapping was only to one\n",
    "print(fire_incidents_df['incident_number'].count())\n",
    "print(fire_incidents_df['incident_number'].nunique())\n",
    "print(fire_incidents_parcel_df['incident_number'].count())\n",
    "print(fire_incidents_parcel_df['incident_number'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "414c4ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6393"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "There are a lot of incidents that do not match a parcel. Based on a review of these incidents these occur at intersections\n",
    "primarily and are not related to building fires (e.g. car fire, etc.). Therefore, we can drop these at this point as\n",
    "they do not pertain to our question of R-2 building and fire inspections\n",
    "'''\n",
    "fire_incidents_parcel_df['parcel_number'].nunique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a986e467",
   "metadata": {},
   "outputs": [],
   "source": [
    "#per comment above, remove fire incidents not linked with parcel as these are not building related (unless tagged wrong but let's assume this for now)\n",
    "#drop geometry columns for now as Postgres can't handle and we've already matched to parcel which is our join key moving forward\n",
    "fire_incidents_final = fire_incidents_parcel_df[~fire_incidents_parcel_df['parcel_number'].isna()]\n",
    "fire_incidents_final = fire_incidents_final.drop(['index_right','point','geometry'],axis=1).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0da546ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table uploaded\n"
     ]
    }
   ],
   "source": [
    "tablename = 'fire_incidents_test'\n",
    "upload_to_postgres(fire_incidents_final, postgres_connstr, tablename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0763c933",
   "metadata": {},
   "source": [
    "## Import Assessor Data\n",
    "- We need to link parcels with the appropriate property metadata using parcel number as a join key.\n",
    "- Using the spatial joins, all of our fire/dbi datasets will have parcel number associated with the record.\n",
    "- Assessor data has important metadata (e.g. construction date) which could help us determine high risk properties.\n",
    "- Take 2014 as it is most accurate (per problem statement).\n",
    "- Upload to Postgres for additional transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "882a5c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = \"closed_roll_year=2014\" #per the problem statement 2014 data is most accurate so we will use that\n",
    "pulltype = 'all'\n",
    "assessor_endpoint = 'wv5m-vpq2'\n",
    "assessor_df = pull_opensf_data(site, \n",
    "                              assessor_endpoint, \n",
    "                              app_token, \n",
    "                              api_key_id, \n",
    "                              api_secret_key,\n",
    "                              pulltype,\n",
    "                              filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b888f9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#break apart lat/long so we can upload and use to count distinct parcels on the same area\n",
    "#we need to do this for condo's to get the true number of units on the same location\n",
    "#This method ended up not being used for the final analysis but helped in our understanding of the records and could \n",
    "#be useful in future analyses.\n",
    "key_col = 'parcel_number'\n",
    "col_name = 'the_geom'\n",
    "int_assessor_df = extract_coordinates(assessor_df,\n",
    "                                      key_col,\n",
    "                                      col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff6510a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing to make sure our date types transfer correctly\n",
    "int_assessor_df['number_of_units'] = int_assessor_df['number_of_units'].astype(float).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b93f699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "816"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Upload data to postgres database (running locally) to create extract and allow some joins to be done in SQL\n",
    "tablename = 'assessor_raw'\n",
    "upload_to_postgres(int_assessor_df, postgres_connstr, tablename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e06b3a6",
   "metadata": {},
   "source": [
    "## Import Fire Inspections\n",
    "- Pull fire inspections and spatially join with parcels to add parcel_number to dataframe\n",
    "- The inspections include violations but violations table has additional information. Join in SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a4567b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pulltype = 'all'\n",
    "fire_inspections_endpoint = 'wb4c-6hwj'\n",
    "fire_inspec_df = pull_opensf_data(site, \n",
    "                              fire_inspections_endpoint, \n",
    "                              app_token, \n",
    "                              api_key_id, \n",
    "                              api_secret_key,\n",
    "                              pulltype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4039b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spatial join, although dbi inspections actually has block number and lot number (parcel number when combined)\n",
    "spatial_txt = 'location'\n",
    "fire_inspec_df, fire_inspec_parcel_df = spatial_join(fire_inspec_df, \n",
    "                                                           spatial_txt, \n",
    "                                                           final_parcels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b6e9dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inspection_number</th>\n",
       "      <th>inspection_type</th>\n",
       "      <th>inspection_type_description</th>\n",
       "      <th>address</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>battalion</th>\n",
       "      <th>station</th>\n",
       "      <th>bfp_district</th>\n",
       "      <th>billable_inspection</th>\n",
       "      <th>inspection_start_date</th>\n",
       "      <th>...</th>\n",
       "      <th>referral_number</th>\n",
       "      <th>interest_amount</th>\n",
       "      <th>penalty_amount</th>\n",
       "      <th>posting_fee</th>\n",
       "      <th>corrective_action_date</th>\n",
       "      <th>referral_agency</th>\n",
       "      <th>lien_date</th>\n",
       "      <th>geometry</th>\n",
       "      <th>index_right</th>\n",
       "      <th>parcel_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14575</td>\n",
       "      <td>04</td>\n",
       "      <td>Complaint Inspection</td>\n",
       "      <td>832  Folsom St</td>\n",
       "      <td>94103</td>\n",
       "      <td>03</td>\n",
       "      <td>01</td>\n",
       "      <td>03S</td>\n",
       "      <td>False</td>\n",
       "      <td>2005-09-23T00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-122.40232 37.78158)</td>\n",
       "      <td>136715.0</td>\n",
       "      <td>3733017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>493175</td>\n",
       "      <td>53</td>\n",
       "      <td>Entertainment Com. Ref. Insp.</td>\n",
       "      <td>494  - 498 14th St</td>\n",
       "      <td>94103</td>\n",
       "      <td>02</td>\n",
       "      <td>36</td>\n",
       "      <td>02S</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-01-11T00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-122.42417 37.76822)</td>\n",
       "      <td>121386.0</td>\n",
       "      <td>3533026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85368</td>\n",
       "      <td>05</td>\n",
       "      <td>Permit Approval Inspection</td>\n",
       "      <td>698  02nd St</td>\n",
       "      <td>94107</td>\n",
       "      <td>03</td>\n",
       "      <td>08</td>\n",
       "      <td>03S</td>\n",
       "      <td>False</td>\n",
       "      <td>2010-07-15T00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-122.39105 37.78055)</td>\n",
       "      <td>148343.0</td>\n",
       "      <td>3788006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93797</td>\n",
       "      <td>02</td>\n",
       "      <td>Follow Up Inspection</td>\n",
       "      <td>698  02nd St</td>\n",
       "      <td>94107</td>\n",
       "      <td>03</td>\n",
       "      <td>08</td>\n",
       "      <td>03S</td>\n",
       "      <td>False</td>\n",
       "      <td>2010-11-19T00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-122.39105 37.78055)</td>\n",
       "      <td>148343.0</td>\n",
       "      <td>3788006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93873</td>\n",
       "      <td>01</td>\n",
       "      <td>Initial Inspection</td>\n",
       "      <td>698  02nd St</td>\n",
       "      <td>94107</td>\n",
       "      <td>03</td>\n",
       "      <td>08</td>\n",
       "      <td>03S</td>\n",
       "      <td>False</td>\n",
       "      <td>2010-11-19T00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-122.39105 37.78055)</td>\n",
       "      <td>148343.0</td>\n",
       "      <td>3788006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  inspection_number inspection_type    inspection_type_description  \\\n",
       "0             14575              04           Complaint Inspection   \n",
       "1            493175              53  Entertainment Com. Ref. Insp.   \n",
       "2             85368              05     Permit Approval Inspection   \n",
       "3             93797              02           Follow Up Inspection   \n",
       "4             93873              01             Initial Inspection   \n",
       "\n",
       "              address zipcode battalion station bfp_district  \\\n",
       "0      832  Folsom St   94103        03      01          03S   \n",
       "1  494  - 498 14th St   94103        02      36          02S   \n",
       "2        698  02nd St   94107        03      08          03S   \n",
       "3        698  02nd St   94107        03      08          03S   \n",
       "4        698  02nd St   94107        03      08          03S   \n",
       "\n",
       "   billable_inspection inspection_start_date  ... referral_number  \\\n",
       "0                False   2005-09-23T00:00:00  ...             NaN   \n",
       "1                False   2023-01-11T00:00:00  ...             NaN   \n",
       "2                False   2010-07-15T00:00:00  ...             NaN   \n",
       "3                False   2010-11-19T00:00:00  ...             NaN   \n",
       "4                False   2010-11-19T00:00:00  ...             NaN   \n",
       "\n",
       "  interest_amount penalty_amount posting_fee  corrective_action_date  \\\n",
       "0             NaN            NaN         NaN                     NaN   \n",
       "1             NaN            NaN         NaN                     NaN   \n",
       "2             NaN            NaN         NaN                     NaN   \n",
       "3             NaN            NaN         NaN                     NaN   \n",
       "4             NaN            NaN         NaN                     NaN   \n",
       "\n",
       "  referral_agency lien_date                     geometry index_right  \\\n",
       "0             NaN       NaN  POINT (-122.40232 37.78158)    136715.0   \n",
       "1             NaN       NaN  POINT (-122.42417 37.76822)    121386.0   \n",
       "2             NaN       NaN  POINT (-122.39105 37.78055)    148343.0   \n",
       "3             NaN       NaN  POINT (-122.39105 37.78055)    148343.0   \n",
       "4             NaN       NaN  POINT (-122.39105 37.78055)    148343.0   \n",
       "\n",
       "  parcel_number  \n",
       "0       3733017  \n",
       "1       3533026  \n",
       "2       3788006  \n",
       "3       3788006  \n",
       "4       3788006  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire_inspec_parcel_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1dad05a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369743\n",
      "369257\n",
      "378382\n",
      "369257\n"
     ]
    }
   ],
   "source": [
    "#Check if we're duplicating data. This is looking OK, a few duplicates but nothing to worry too much about at this point\n",
    "#There are a few points mapping to multiple parcels but we can take care of that later. If this was a longer project\n",
    "#Could do some additional spatial logic to make sure mapping was only to one\n",
    "print(fire_inspec_df['inspection_number'].count())\n",
    "print(fire_inspec_df['inspection_number'].nunique())\n",
    "print(fire_inspec_parcel_df['inspection_number'].count())\n",
    "print(fire_inspec_parcel_df['inspection_number'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e22b494f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13525"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We're missing about 5% in the spatially join but at this level of analysis I think it is acceptable.\n",
    "# If time permits, I will circle back and see why\n",
    "fire_inspec_parcel_df[fire_inspec_parcel_df['parcel_number'].isna()]['inspection_number'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b0568e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop these fields as postgres won't like and we have parcel now. \n",
    "fire_inspec_parcel_df = fire_inspec_parcel_df.drop(['location','geometry'],axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c4af4e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing to make sure our date types transfer correctly\n",
    "fire_inspec_parcel_df['inspection_start_date'] = pd.to_datetime(fire_inspec_parcel_df['inspection_start_date'], errors='coerce')\n",
    "fire_inspec_parcel_df['inspection_end_date'] = pd.to_datetime(fire_inspec_parcel_df['inspection_end_date'], errors='coerce')\n",
    "fire_inspec_parcel_df['return_date'] = pd.to_datetime(fire_inspec_parcel_df['return_date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "02964fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns containing \"@\" in their names\n",
    "columns_to_drop = fire_inspec_parcel_df.filter(regex='@', axis=1).columns\n",
    "fire_inspec_parcel_df.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "568263df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Upload data to postgres database (running locally) to create extract and allow some joins to be done in SQL\n",
    "tablename = 'fire_inspection_raw'\n",
    "upload_to_postgres(fire_inspec_parcel_df, postgres_connstr, tablename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49ca817",
   "metadata": {},
   "source": [
    "## Fire Violations\n",
    "- Pull down the fire violations dataset using the API.\n",
    "- Spatially join with parcels.\n",
    "- Upload to Postgres Database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0d0e7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pulltype = 'all'\n",
    "fire_violations_endpoint = '4zuq-2cbe'\n",
    "fire_vio_df = pull_opensf_data(site, \n",
    "                              fire_violations_endpoint, \n",
    "                              app_token, \n",
    "                              api_key_id, \n",
    "                              api_secret_key,\n",
    "                              pulltype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1628136",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spatial join, although dbi inspections actually has block number and lot number (parcel number when combined)\n",
    "spatial_txt = 'location'\n",
    "fire_vio_df, fire_vio_parcel_df = spatial_join(fire_vio_df, \n",
    "                                                spatial_txt, \n",
    "                                                final_parcels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90bab2c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inspection_number</th>\n",
       "      <th>violation_id</th>\n",
       "      <th>address</th>\n",
       "      <th>battalion</th>\n",
       "      <th>station</th>\n",
       "      <th>bfp_district</th>\n",
       "      <th>close_date</th>\n",
       "      <th>corrective_action</th>\n",
       "      <th>status</th>\n",
       "      <th>violation_item_description</th>\n",
       "      <th>...</th>\n",
       "      <th>:@computed_region_p5aj_wyqh</th>\n",
       "      <th>:@computed_region_jwn9_ihcz</th>\n",
       "      <th>:@computed_region_6qbp_sg9q</th>\n",
       "      <th>:@computed_region_qgnn_b9vv</th>\n",
       "      <th>:@computed_region_26cr_cadq</th>\n",
       "      <th>:@computed_region_6ezc_tdp2</th>\n",
       "      <th>:@computed_region_h4ep_8xdi</th>\n",
       "      <th>geometry</th>\n",
       "      <th>index_right</th>\n",
       "      <th>parcel_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>294593</td>\n",
       "      <td>1610-0045SFC13EY</td>\n",
       "      <td>9991  Unk Airport</td>\n",
       "      <td>AP</td>\n",
       "      <td>AP</td>\n",
       "      <td>AP</td>\n",
       "      <td>2022-12-26T00:00:00</td>\n",
       "      <td>correct - no permit</td>\n",
       "      <td>abated</td>\n",
       "      <td>2013 san francisco fire code</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-122.38159 37.62391)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>185687</td>\n",
       "      <td>1404-001213PER01Y</td>\n",
       "      <td>900  North Access Rd</td>\n",
       "      <td>AP</td>\n",
       "      <td>AP</td>\n",
       "      <td>AP</td>\n",
       "      <td>2014-04-07T00:00:00</td>\n",
       "      <td>correct - no permit</td>\n",
       "      <td>closed</td>\n",
       "      <td>permit / general</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-122.38636 37.63719)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>199268</td>\n",
       "      <td>1410-002613EXT04</td>\n",
       "      <td>400  Upper Domestic Loop</td>\n",
       "      <td>AP</td>\n",
       "      <td>AP</td>\n",
       "      <td>AP</td>\n",
       "      <td>2015-07-24T00:00:00</td>\n",
       "      <td>obtain permit</td>\n",
       "      <td>closed</td>\n",
       "      <td>extinguisher / service required</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-122.38503 37.61779)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1706-013516SPR08Y</td>\n",
       "      <td>776  Bush St</td>\n",
       "      <td>01</td>\n",
       "      <td>02</td>\n",
       "      <td>01W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>open</td>\n",
       "      <td>sprinkler / 5-year service</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-122.41004 37.79026)</td>\n",
       "      <td>13174.0</td>\n",
       "      <td>0273008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>378677</td>\n",
       "      <td>1903-0278NOTES</td>\n",
       "      <td>1  Trenton St</td>\n",
       "      <td>01</td>\n",
       "      <td>02</td>\n",
       "      <td>01N</td>\n",
       "      <td>2019-04-30T09:14:39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>abated</td>\n",
       "      <td>notes</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-122.40908 37.79508)</td>\n",
       "      <td>8656.0</td>\n",
       "      <td>0192006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  inspection_number       violation_id                   address battalion  \\\n",
       "0            294593   1610-0045SFC13EY         9991  Unk Airport        AP   \n",
       "1            185687  1404-001213PER01Y      900  North Access Rd        AP   \n",
       "2            199268   1410-002613EXT04  400  Upper Domestic Loop        AP   \n",
       "3               NaN  1706-013516SPR08Y              776  Bush St        01   \n",
       "4            378677     1903-0278NOTES             1  Trenton St        01   \n",
       "\n",
       "  station bfp_district           close_date    corrective_action  status  \\\n",
       "0      AP           AP  2022-12-26T00:00:00  correct - no permit  abated   \n",
       "1      AP           AP  2014-04-07T00:00:00  correct - no permit  closed   \n",
       "2      AP           AP  2015-07-24T00:00:00        obtain permit  closed   \n",
       "3      02          01W                  NaN                  NaN    open   \n",
       "4      02          01N  2019-04-30T09:14:39                  NaN  abated   \n",
       "\n",
       "        violation_item_description  ... :@computed_region_p5aj_wyqh  \\\n",
       "0     2013 san francisco fire code  ...                         NaN   \n",
       "1                 permit / general  ...                         NaN   \n",
       "2  extinguisher / service required  ...                         NaN   \n",
       "3       sprinkler / 5-year service  ...                           1   \n",
       "4                            notes  ...                           1   \n",
       "\n",
       "  :@computed_region_jwn9_ihcz :@computed_region_6qbp_sg9q  \\\n",
       "0                         NaN                         NaN   \n",
       "1                         NaN                         NaN   \n",
       "2                         NaN                         NaN   \n",
       "3                          16                          16   \n",
       "4                         104                         104   \n",
       "\n",
       "  :@computed_region_qgnn_b9vv :@computed_region_26cr_cadq  \\\n",
       "0                         NaN                         NaN   \n",
       "1                         NaN                         NaN   \n",
       "2                         NaN                         NaN   \n",
       "3                           6                           3   \n",
       "4                           6                           3   \n",
       "\n",
       "  :@computed_region_6ezc_tdp2 :@computed_region_h4ep_8xdi  \\\n",
       "0                         NaN                         NaN   \n",
       "1                         NaN                         NaN   \n",
       "2                         NaN                         NaN   \n",
       "3                         NaN                         NaN   \n",
       "4                         NaN                         NaN   \n",
       "\n",
       "                      geometry index_right parcel_number  \n",
       "0  POINT (-122.38159 37.62391)         NaN           NaN  \n",
       "1  POINT (-122.38636 37.63719)         NaN           NaN  \n",
       "2  POINT (-122.38503 37.61779)         NaN           NaN  \n",
       "3  POINT (-122.41004 37.79026)     13174.0       0273008  \n",
       "4  POINT (-122.40908 37.79508)      8656.0       0192006  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire_vio_parcel_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "605baaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38228\n",
      "14134\n",
      "39419\n",
      "14134\n"
     ]
    }
   ],
   "source": [
    "#Check if we're duplicating data. This is looking OK, a few duplicates but nothing to worry too much about at this point\n",
    "#There are a few points mapping to multiple parcels but we can take care of that later. If this was a longer project\n",
    "#Could do some additional spatial logic to make sure mapping was only to one\n",
    "print(fire_vio_df['inspection_number'].count())\n",
    "print(fire_vio_df['inspection_number'].nunique())\n",
    "print(fire_vio_parcel_df['inspection_number'].count())\n",
    "print(fire_vio_parcel_df['inspection_number'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c0567ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "460"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We're missing about 1% in the spatial join but at this level of analysis I think it is acceptable.\n",
    "# If time permits, I will circle back and see why\n",
    "fire_vio_parcel_df[fire_vio_parcel_df['parcel_number'].isna()]['inspection_number'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9119e5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop these fields as postgres won't like and we have parcel now. \n",
    "fire_vio_parcel_df = fire_vio_parcel_df.drop(['location','geometry'],axis=1).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "792ef93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functionalize this for future...\n",
    "#Preprocessing to make sure our date types transfer correctly\n",
    "fire_vio_parcel_df['close_date'] = pd.to_datetime(fire_vio_parcel_df['close_date'], errors='coerce')\n",
    "fire_vio_parcel_df['violation_date'] = pd.to_datetime(fire_vio_parcel_df['violation_date'], errors='coerce')\n",
    "# Drop columns containing \"@\" in their names\n",
    "columns_to_drop = fire_vio_parcel_df.filter(regex='@', axis=1).columns\n",
    "fire_vio_parcel_df.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "590edbda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Upload data to postgres database (running locally) to create extract and allow some joins to be done in SQL\n",
    "tablename = 'fire_violations_raw'\n",
    "upload_to_postgres(fire_vio_parcel_df, postgres_connstr, tablename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badbf870",
   "metadata": {},
   "source": [
    "## Import DBI Violations\n",
    "- Download via API\n",
    "- Join with parcels if possible, although DBI inspections data actually has block/lot number. Join anyway to check spatial joining methodology.\n",
    "- Upload to postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cdaf09dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = 'location IS NOT NULL' #going to start by filtering out data without a parcel because we cannot tell anything about building type without this if using parcel to join\n",
    "pulltype = 'all'\n",
    "dbi_violoations_endpoint = 'nbtm-fbw5'\n",
    "dbi_vio_df = pull_opensf_data(site, \n",
    "                              dbi_violoations_endpoint, \n",
    "                              app_token, \n",
    "                              api_key_id, \n",
    "                              api_secret_key,\n",
    "                              pulltype,\n",
    "                              filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bef22d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complaint_number</th>\n",
       "      <th>item_sequence_number</th>\n",
       "      <th>date_filed</th>\n",
       "      <th>block</th>\n",
       "      <th>lot</th>\n",
       "      <th>street_number</th>\n",
       "      <th>street_name</th>\n",
       "      <th>street_suffix</th>\n",
       "      <th>status</th>\n",
       "      <th>receiving_division</th>\n",
       "      <th>assigned_division</th>\n",
       "      <th>nov_category_description</th>\n",
       "      <th>item</th>\n",
       "      <th>neighborhoods_analysis_boundaries</th>\n",
       "      <th>supervisor_district</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>location</th>\n",
       "      <th>unit</th>\n",
       "      <th>nov_item_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>199705272</td>\n",
       "      <td>8127</td>\n",
       "      <td>1997-04-18T00:00:00.000</td>\n",
       "      <td>0281</td>\n",
       "      <td>017</td>\n",
       "      <td>1035</td>\n",
       "      <td>Bush</td>\n",
       "      <td>St</td>\n",
       "      <td>not active</td>\n",
       "      <td>Housing Inspection Services</td>\n",
       "      <td>Housing Inspection Services</td>\n",
       "      <td>other section</td>\n",
       "      <td>inspector comments</td>\n",
       "      <td>Nob Hill</td>\n",
       "      <td>3</td>\n",
       "      <td>94109</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [-122.4142531...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>199919693</td>\n",
       "      <td>29804</td>\n",
       "      <td>1999-03-08T00:00:00.000</td>\n",
       "      <td>3643</td>\n",
       "      <td>015A</td>\n",
       "      <td>3356</td>\n",
       "      <td>24th</td>\n",
       "      <td>St</td>\n",
       "      <td>not active</td>\n",
       "      <td>Department Of Bldg Inspection</td>\n",
       "      <td>Housing Inspection Services</td>\n",
       "      <td>other section</td>\n",
       "      <td>inspector comments</td>\n",
       "      <td>Mission</td>\n",
       "      <td>9</td>\n",
       "      <td>94110</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [-122.4198301...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200447766</td>\n",
       "      <td>142256</td>\n",
       "      <td>2004-02-18T00:00:00.000</td>\n",
       "      <td>2800</td>\n",
       "      <td>006</td>\n",
       "      <td>899</td>\n",
       "      <td>Corbett</td>\n",
       "      <td>Av</td>\n",
       "      <td>not active</td>\n",
       "      <td>Housing Inspection Services</td>\n",
       "      <td>Housing Inspection Services</td>\n",
       "      <td>building section</td>\n",
       "      <td>unit 1</td>\n",
       "      <td>Twin Peaks</td>\n",
       "      <td>8</td>\n",
       "      <td>94131</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [-122.4434596...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200448900</td>\n",
       "      <td>144671</td>\n",
       "      <td>2004-03-30T00:00:00.000</td>\n",
       "      <td>3726</td>\n",
       "      <td>052</td>\n",
       "      <td>525</td>\n",
       "      <td>Natoma</td>\n",
       "      <td>St</td>\n",
       "      <td>active</td>\n",
       "      <td>Housing Inspection Services</td>\n",
       "      <td>Housing Inspection Services</td>\n",
       "      <td>other section</td>\n",
       "      <td>inspectors comments</td>\n",
       "      <td>South of Market</td>\n",
       "      <td>6</td>\n",
       "      <td>94103</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [-122.4081877...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200448376</td>\n",
       "      <td>143283</td>\n",
       "      <td>2004-03-11T00:00:00.000</td>\n",
       "      <td>0131</td>\n",
       "      <td>007</td>\n",
       "      <td>1309</td>\n",
       "      <td>Grant</td>\n",
       "      <td>Av</td>\n",
       "      <td>not active</td>\n",
       "      <td>Housing Inspection Services</td>\n",
       "      <td>Housing Inspection Services</td>\n",
       "      <td>building section</td>\n",
       "      <td>x</td>\n",
       "      <td>North Beach</td>\n",
       "      <td>3</td>\n",
       "      <td>94133</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [-122.4074470...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  complaint_number item_sequence_number               date_filed block   lot  \\\n",
       "0        199705272                 8127  1997-04-18T00:00:00.000  0281   017   \n",
       "1        199919693                29804  1999-03-08T00:00:00.000  3643  015A   \n",
       "2        200447766               142256  2004-02-18T00:00:00.000  2800   006   \n",
       "3        200448900               144671  2004-03-30T00:00:00.000  3726   052   \n",
       "4        200448376               143283  2004-03-11T00:00:00.000  0131   007   \n",
       "\n",
       "  street_number street_name street_suffix      status  \\\n",
       "0          1035        Bush            St  not active   \n",
       "1          3356        24th            St  not active   \n",
       "2           899     Corbett            Av  not active   \n",
       "3           525      Natoma            St      active   \n",
       "4          1309       Grant            Av  not active   \n",
       "\n",
       "              receiving_division            assigned_division  \\\n",
       "0    Housing Inspection Services  Housing Inspection Services   \n",
       "1  Department Of Bldg Inspection  Housing Inspection Services   \n",
       "2    Housing Inspection Services  Housing Inspection Services   \n",
       "3    Housing Inspection Services  Housing Inspection Services   \n",
       "4    Housing Inspection Services  Housing Inspection Services   \n",
       "\n",
       "  nov_category_description                 item  \\\n",
       "0            other section   inspector comments   \n",
       "1            other section   inspector comments   \n",
       "2         building section               unit 1   \n",
       "3            other section  inspectors comments   \n",
       "4         building section                    x   \n",
       "\n",
       "  neighborhoods_analysis_boundaries supervisor_district zipcode  \\\n",
       "0                          Nob Hill                   3   94109   \n",
       "1                           Mission                   9   94110   \n",
       "2                        Twin Peaks                   8   94131   \n",
       "3                   South of Market                   6   94103   \n",
       "4                       North Beach                   3   94133   \n",
       "\n",
       "                                            location unit nov_item_description  \n",
       "0  {'type': 'Point', 'coordinates': [-122.4142531...  NaN                  NaN  \n",
       "1  {'type': 'Point', 'coordinates': [-122.4198301...  NaN                  NaN  \n",
       "2  {'type': 'Point', 'coordinates': [-122.4434596...  NaN                  NaN  \n",
       "3  {'type': 'Point', 'coordinates': [-122.4081877...  NaN                  NaN  \n",
       "4  {'type': 'Point', 'coordinates': [-122.4074470...  NaN                  NaN  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbi_vio_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16d91287",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spatial join, although dbi inspections actually has block number and lot number (parcel number when combined)\n",
    "spatial_txt = 'location'\n",
    "dbi_vio_df, dbi_vio_parcel_df = spatial_join(dbi_vio_df, \n",
    "                                                spatial_txt, \n",
    "                                                final_parcels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b392f1f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This almost seems too good in terms of no missing parcels after the join. Checks confirm it is correct.\n",
    "dbi_vio_parcel_df[dbi_vio_parcel_df['parcel_number'].isna()]['complaint_number'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8da1e0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop these fields as postgres won't like and we have parcel now. \n",
    "dbi_vio_parcel_df = dbi_vio_parcel_df.drop(['location','geometry'],axis=1).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9ac706d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functionalize this for future...\n",
    "#Preprocessing to make sure our date types transfer correctly\n",
    "dbi_vio_parcel_df['date_filed'] = pd.to_datetime(dbi_vio_parcel_df['date_filed'], errors='coerce')\n",
    "# Drop columns containing \"@\" in their names\n",
    "columns_to_drop = dbi_vio_parcel_df.filter(regex='@', axis=1).columns\n",
    "dbi_vio_parcel_df.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "06560b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "387"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Upload data to postgres database (running locally) to create extract and allow some joins to be done in SQL\n",
    "tablename = 'dbi_violations_raw'\n",
    "upload_to_postgres(dbi_vio_parcel_df, postgres_connstr, tablename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bf312d",
   "metadata": {},
   "source": [
    "## Import DBI Inspection Complaints\n",
    "- Download, join, pre-process, upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ddc3b081",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this dataset has parcel number baked in and we have it for most records!\n",
    "#let's filter if parcel is missing and if it's not assigned to DBI (for now)\n",
    "filters = 'parcel_number IS NOT NULL AND LOWER(assigned_division) = \"housing inspection services\"' \n",
    "\n",
    "pulltype = 'all'\n",
    "dbi_inspec_endpoint = 'gm2e-bten'\n",
    "dbi_inspec_df = pull_opensf_data(site, \n",
    "                              dbi_inspec_endpoint, \n",
    "                              app_token, \n",
    "                              api_key_id, \n",
    "                              api_secret_key,\n",
    "                              pulltype,\n",
    "                              filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8f977622",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert dates to date types\n",
    "dbi_inspec_df['date_filed'] = pd.to_datetime(dbi_inspec_df['date_filed'], errors='coerce')\n",
    "dbi_inspec_df['closed_date'] = pd.to_datetime(dbi_inspec_df['closed_date'], errors='coerce')\n",
    "dbi_inspec_df['date_1st_nov_issued'] = pd.to_datetime(dbi_inspec_df['date_1st_nov_issued'], errors='coerce')\n",
    "dbi_inspec_df['date_abated'] = pd.to_datetime(dbi_inspec_df['date_abated'], errors='coerce')\n",
    "dbi_inspec_df['date_2nd_nov_issued'] = pd.to_datetime(dbi_inspec_df['date_2nd_nov_issued'], errors='coerce')\n",
    "dbi_inspec_df['date_referred_to_city_attorney'] = pd.to_datetime(dbi_inspec_df['date_referred_to_city_attorney'], errors='coerce')\n",
    "dbi_inspec_df['date_final_warning_letter_issued'] = pd.to_datetime(dbi_inspec_df['date_final_warning_letter_issued'], errors='coerce')\n",
    "dbi_inspec_df['director_hearing_date'] = pd.to_datetime(dbi_inspec_df['director_hearing_date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0411dbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbi_inspec_df.drop(['point'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "55d5752f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "474"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Upload data to postgres database (running locally) to create extract and allow some joins to be done in SQL\n",
    "tablename = 'dbi_inspections_raw'\n",
    "upload_to_postgres(dbi_inspec_df, postgres_connstr, tablename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7393fb5a",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "- Now that data has been extracted from API and loaded into SQL, we will investigate data further in pgAdmin and write transformations in SQL to join data, feature engineer, etc.\n",
    "- In production, our SQL transformations would be managed by something like dbt but for the purposes of this project that has not been set-up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65209184",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
